{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyND8Q8tJWAJzq3ck/+7GGsa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel-wei/yolov5/blob/master/detectTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl2aUStdaqEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# utf-8\n",
        "\"\"\"\n",
        "    Copyright sharebee.cn, Inc, All Rights Reserved\n",
        "    Author: Samuel\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "    Reference: https://www.curiousily.com/posts/object-detection-on-custom\\\n",
        "    -dataset-with-yolo-v5-using-pytorch-and-python/\n",
        "\"\"\"\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import json\n",
        "import urllib\n",
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "#%matplotlib inline\n",
        "#%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 10\n",
        "\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhYlzgGJbj5B",
        "colab_type": "text"
      },
      "source": [
        "# Each line in the dataset file contains a JSON object. Let's create a list of all annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DurQBysJbS3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "clothing = []\n",
        "with open('clothing.json') as f:\n",
        "    for line in f:\n",
        "        clothing.append(json.loads(line))\n",
        "# Here's an example annotation:\n",
        "print(clothing[0])\n",
        "\n",
        "for c in clothing:\n",
        "    if len(c['annotation']) > 1:\n",
        "        display(c)\n",
        "\n",
        "# all unique categories\n",
        "categoris = []\n",
        "for c in clothing:\n",
        "    for a in c['annotation']:\n",
        "        categories.extend(a['label'])\n",
        "categories = list(set(categories))\n",
        "categories.sort()\n",
        "print(categories)\n",
        "\n",
        "# split the data into a training and validation set\n",
        "train_clothing, val_clothing = train_test_split(clothing, test_size=0.1)\n",
        "len(train_clothing), len(val_clothing)\n",
        "\n",
        "# an image from dataset, start by downloading it\n",
        "row = train_clothing[10]\n",
        "img = urllib.request.urlopen(row['content'])\n",
        "img = Image.open(img)\n",
        "img = img.convert('RGB')\n",
        "\n",
        "img.save('demo_image.jpeg', 'JPEG')\n",
        "\n",
        "print(row)\n",
        "\n",
        "# OpenCV to read the image\n",
        "img = cv2.cvtColor(cv2.imread(f'demo_image.jpeg'), cv2.COLOR_BGR2BGRA)\n",
        "print(img.shape)\n",
        "\n",
        "# add the bounding box on top of the image along with the label\n",
        "for a in row['annotation']:\n",
        "    for label in a['label']:\n",
        "\n",
        "        w = a['imageWidth']\n",
        "        h = a['imageHeight']\n",
        "\n",
        "        points = a['points']\n",
        "        p1, p2 = points\n",
        "\n",
        "        x1, y1 = p1['x'] * w, p1['y'] * h\n",
        "        x2, y2 = p2['x'] * w, p2['y'] * h\n",
        "\n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            (int(x1), int(y2)),\n",
        "            (int(x2), int(y2)),\n",
        "            color=(0, 255, 0),\n",
        "            thickness=2\n",
        "        )\n",
        "\n",
        "        ((label_width), (label_height), _) = cv2.getTextSize(\n",
        "            label,\n",
        "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
        "            fontScale=1.75,\n",
        "            thickness=2\n",
        "        )\n",
        "\n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            (int(x1), int(y1)),\n",
        "            (int(x1 + label_width + label+width * 0.05), int(y1 + label_height + label_height * 0.025)),\n",
        "            color=(0, 255, 0),\n",
        "            thickness=cv2.FILLED\n",
        "\n",
        "        )\n",
        "\n",
        "        cv2.putText(\n",
        "            img,\n",
        "            label,\n",
        "            org=(int(x1), int(y1 + label_height + label_height * 0.025)), # bottom left\n",
        "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
        "            fontScale=1.75,\n",
        "            color=(255, 255, 255),\n",
        "            thickness=2\n",
        "        )\n",
        "# result:\n",
        "plt.imshow(img)\n",
        "plt.axis('off');\n",
        "\n",
        "\"\"\"\n",
        "    One txt with labels file per image\n",
        "    One row per object\n",
        "    Each row contains: class_index bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "    Box coordinates must be normalized between 0 and 1\n",
        "\"\"\"\n",
        "def create_dataset(clothing, categories, dataset_type):\n",
        "    images_path = Path(f'clothing/labels/{dataset_type}')\n",
        "    labels_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img_id, row in enumerate(tqdm(clothing)):\n",
        "        image_name = f\"{img_id}.jpeg\"\n",
        "\n",
        "        img = urllib.request.urlopen(row['content'])\n",
        "        img = Image.open(img)\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "        img.save(str(images_path / image_name), 'JPEG')\n",
        "\n",
        "        label_name = f\"{img_id}.txt\"\n",
        "\n",
        "        with (labels_path / label_name).open(mode='w') as label_file:\n",
        "            for a in row['annotation']:\n",
        "                for label in a['label']:\n",
        "                    category_idx = categories.index(label)\n",
        "                    points = a['points']\n",
        "                    p1, p2 = points\n",
        "                    x1, y1 = p1['x'], p1['y']\n",
        "                    x2, y2 = p2['x'], p2['y']\n",
        "\n",
        "                    bbox_width = x2 - x1\n",
        "                    bbox_height = y2 - y1\n",
        "\n",
        "                    label_file.write(\n",
        "                        f\"{category_idx} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
        "                    )\n",
        "create_dataset(train_clothing, categories, 'train')\n",
        "create_dataset(val_clothing, categories, 'val')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}